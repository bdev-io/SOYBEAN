{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6122c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pgeocode\n",
    "import geopandas as gpd\n",
    "\n",
    "# Raw Dataset\n",
    "raw_df = pd.read_csv('../dataset/annualy.csv')\n",
    "\n",
    "# GEOID -> Location\n",
    "gdf = gpd.read_file(\"../dataset/tl_2024_us_county.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ef83a",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e16ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/KUUWANGE/WORKSPACE/P_Personal/SOYBEAN/results'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.path.join(os.path.curdir, '../results')\n",
    "BASE_PATH = os.path.abspath(BASE_PATH)\n",
    "\n",
    "BASE_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09348808",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5740850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 재정렬 / 컬럼명 정리\n",
    "\n",
    "df = raw_df.rename(columns={\n",
    "    'COMMODITY_DESC': 'crop',\n",
    "    'YEAR': 'year',\n",
    "    'STATE_NAME': 'state',\n",
    "    \"COUNTRY_NAME\": \"country\",\n",
    "    'COUNTY_NAME': 'county',\n",
    "    'DOMAIN_DESC': 'domain',\n",
    "    'STATISTICCAT_DESC': 'type',\n",
    "    'UNIT_DESC': 'unit',\n",
    "    'VALUE': 'value',\n",
    "    'LOCATION_DESC': 'loc',\n",
    "    'COUNTRY_CODE': 'country_code',\n",
    "    'STATE_FIPS_CODE': 'state_fips',\n",
    "    'COUNTY_CODE': 'county_code'\n",
    "    }, inplace=False).copy()\n",
    "df = df[['crop', 'year', 'country',  'country_code',  'state', 'state_fips',  'county', 'county_code', 'type', 'domain', 'unit', 'value', 'loc']].copy()\n",
    "df['country_code'] = df['country_code'].astype(int)\n",
    "df['state_fips'] = df['state_fips'].astype(int)\n",
    "df['county_code'] = df['county_code'].astype(int)\n",
    "df = df.sort_values(by=['year', 'state', 'county', 'crop', 'domain', 'type'], ascending=[True, True, True, True, True, True], inplace=False).copy().reset_index(drop=True)\n",
    "\n",
    "df[\"type_unit\"] = df[\"type\"] + \" [\" + df[\"unit\"] + \"]\"\n",
    "df_pivot = df.pivot_table(index=[\"year\", \"state\", \"state_fips\", \"county\", \"county_code\", \"crop\"],\n",
    "    columns=\"type_unit\",\n",
    "    values=\"value\"\n",
    ").reset_index()\n",
    "\n",
    "df_pivot.columns.name = None\n",
    "\n",
    "#raw_data = df.copy()\n",
    "\n",
    "#df.assign(C=df['type'])\n",
    "\n",
    "df_pivot = df_pivot[[\"year\", \"state\", \"state_fips\", \"county\", \"county_code\", \"crop\", \"AREA HARVESTED [ACRES]\", \"AREA PLANTED [ACRES]\", \"YIELD [BU / ACRE]\", \"PRODUCTION [BU]\"]]\n",
    "df_pivot = df_pivot.rename(columns={\n",
    "    'AREA HARVESTED [ACRES]': 'area_harvested',\n",
    "    'AREA PLANTED [ACRES]': 'area_planted',\n",
    "    'YIELD [BU / ACRE]': 'yield',\n",
    "    'PRODUCTION [BU]': 'production'\n",
    "}).copy()\n",
    "\n",
    "df = df_pivot.reset_index(drop=True)\n",
    "\n",
    "raw_data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6750940",
   "metadata": {},
   "source": [
    "## 유틸 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "582d205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds: -118.519477, 44.25509, -116.78371, 45.080746\n",
      "(-118.519477, 44.25509, -116.78371, 45.080746)\n",
      "Bounds: -118.519477, 44.25509, -116.78371, 45.080746\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### STATE_FIPS, COUNTY_FIPS 를 이용하여 LAT / LON, BOUNDARY 가져옴 ( CDMWF 사용 할 용도)\n",
    "def find_boundary(state_fips, county_fips):\n",
    "    filtered_gdf = gdf[(gdf['STATEFP'] == str(state_fips).zfill(2)) & (gdf['COUNTYFP'] == str(county_fips).zfill(3))]\n",
    "    target_row = None\n",
    "    if not filtered_gdf.empty:\n",
    "        target_row = filtered_gdf.iloc[0]['geometry']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if target_row is not None:\n",
    "        (minx, miny, maxx, maxy) = target_row.bounds\n",
    "        print(f\"Bounds: {minx}, {miny}, {maxx}, {maxy}\")\n",
    "        return target_row\n",
    "\n",
    "x = find_boundary(41, 1)\n",
    "print(x.bounds)\n",
    "# bound to lat lon\n",
    "(minlat, minlon, maxlat, maxlon) = x.bounds\n",
    "print(f\"Bounds: {minlat}, {minlon}, {maxlat}, {maxlon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce56164",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af4753",
   "metadata": {},
   "source": [
    "### 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c8124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef8e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/ccmn80ps0ms033hdrcww86kc0000gn/T/ipykernel_71547/2560259120.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sizes = df.groupby(['group']).size()\n"
     ]
    }
   ],
   "source": [
    "## 데이터 정리 및 정규화, 데이터셋 생성\n",
    "\n",
    "df = raw_data.copy()\n",
    "\n",
    "## 데이터프레임중, 2000년 이후의 데이터만 남기기 ( NDVI )\n",
    "\n",
    "df = df[df['year'] >= 2000].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "df['area_harvested'] = df['area_harvested'].replace(np.nan, 0)\n",
    "df['yield'] = df['yield'].replace(np.nan, 0)\n",
    "df['production'] = df['production'].replace(np.nan, 0)\n",
    "df['area_planted'] = df['area_planted'].replace(np.nan, 0)\n",
    "\n",
    "df['time_idx']  = df['year'] - df['year'].min()\n",
    "df['group'] = df['crop'] + \"_\" + df['state'] + \"_\" + df['county']\n",
    "df['group'] = df['group'].astype(\"category\")\n",
    "df['time_idx'] = df['time_idx'].astype(\"int64\")\n",
    "\n",
    "# drop na\n",
    "\n",
    "df = df.dropna(subset=['area_harvested', 'area_planted', 'yield', 'production'], how='any').copy()\n",
    "df = df.dropna(subset=['state', 'county', 'crop'], how='any').copy()\n",
    "df = df.dropna(subset=['time_idx', 'group'], how='any').copy()\n",
    "df = df.dropna(subset=['year'], how='any').copy()\n",
    "df = df.dropna(subset=['state_fips'], how='any').copy()\n",
    "\n",
    "df = df[['time_idx', 'group', 'year', 'state', 'county', 'crop', 'area_harvested', 'area_planted', 'yield', 'production']].copy()\n",
    "\n",
    "sizes = df.groupby(['group']).size()\n",
    "\n",
    "# drop groups with less than 14 rows\n",
    "df = df[df['group'].isin(sizes[sizes >= 14].index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb360987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['group'].isin(['CORN_FLORIDA_BROWARD']) == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3117545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesDataSet[length=108632](\n",
      "\ttime_idx='time_idx',\n",
      "\ttarget='production',\n",
      "\tgroup_ids=['group'],\n",
      "\tweight=None,\n",
      "\tmax_encoder_length=6,\n",
      "\tmin_encoder_length=3,\n",
      "\tmin_prediction_idx=np.int64(0),\n",
      "\tmin_prediction_length=1,\n",
      "\tmax_prediction_length=3,\n",
      "\tstatic_categoricals=['state', 'crop', 'county'],\n",
      "\tstatic_reals=[],\n",
      "\ttime_varying_known_categoricals=None,\n",
      "\ttime_varying_known_reals=['area_harvested', 'year'],\n",
      "\ttime_varying_unknown_categoricals=[],\n",
      "\ttime_varying_unknown_reals=['yield'],\n",
      "\tvariable_groups=None,\n",
      "\tconstant_fill_strategy=None,\n",
      "\tallow_missing_timesteps=True,\n",
      "\tlags=None,\n",
      "\tadd_relative_time_idx=True,\n",
      "\tadd_target_scales=True,\n",
      "\tadd_encoder_length=True,\n",
      "\ttarget_normalizer=GroupNormalizer(\n",
      "\tmethod='standard',\n",
      "\tgroups=['group'],\n",
      "\tcenter=True,\n",
      "\tscale_by_group=False,\n",
      "\ttransformation='softplus',\n",
      "\tmethod_kwargs={}\n",
      "),\n",
      "\tcategorical_encoders={'__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'group': NaNLabelEncoder(add_nan=False, warn=True), 'state': NaNLabelEncoder(add_nan=False, warn=True), 'crop': NaNLabelEncoder(add_nan=False, warn=True), 'county': NaNLabelEncoder(add_nan=False, warn=True)},\n",
      "\tscalers={'encoder_length': StandardScaler(), 'production_center': StandardScaler(), 'production_scale': StandardScaler(), 'area_harvested': StandardScaler(), 'year': StandardScaler(), 'relative_time_idx': StandardScaler(), 'yield': StandardScaler()},\n",
      "\trandomize_length=None,\n",
      "\tpredict_mode=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/data/timeseries.py:1693: UserWarning: If predicting, no randomization should be possible - setting stop_randomization=True\n",
      "  warnings.warn(\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/data/timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 1 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__group': 'CORN_IDAHO_OTHER (COMBINED) COUNTIES'}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_prediction_length = 3\n",
    "max_encoder_length = 6\n",
    "training_cutoff = df[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],  # use all data up to the cutoff\n",
    "    #data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"production\",\n",
    "    group_ids=[\"group\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"state\", \"crop\", \"county\"],\n",
    "    static_reals=[],\n",
    "    # time_varying_known_reals=[col for col in df.columns if \"ndvi_\" in col or \"prec_\" in col or \"temp_\" in col],\n",
    "    time_varying_known_reals=[\"area_harvested\", \"year\"],\n",
    "    time_varying_unknown_reals=[\"yield\"],\n",
    "    #variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    #time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    # time_varying_unknown_reals=[\n",
    "    #     \"volume\",\n",
    "    #     \"log_volume\",\n",
    "    #     \"industry_volume\",\n",
    "    #     \"soda_volume\",\n",
    "    #     \"avg_max_temp\",\n",
    "    #     \"avg_volume_by_agency\",\n",
    "    #     \"avg_volume_by_sku\",\n",
    "    # ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"group\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "print (training)\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=False)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=1, persistent_workers=True)\n",
    "\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=1, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad06ba5",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef440ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 170.7k\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=1e-4, patience=10, verbose=True, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor(logging_interval=\"step\", log_momentum=True)  # log learning rate and momentum\n",
    "logger = TensorBoardLogger(save_dir=os.path.join(BASE_PATH, 'tf_logger'))  # logging results to a tensorboard\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "## (*•؎ •*) 은하수를 여행하는 히치하이커 (*•؎ •*) ##\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    # max_steps=50,\n",
    "    #accelerator=\"cpu\", # tpu / cuda\n",
    "    # accelerator=\"cuda\",\n",
    "    # accelerator=\"cpu\",\n",
    "    # accelerator=,\n",
    "    enable_model_summary=False,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=100,\n",
    "    # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    log_every_n_steps=2,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=42,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.25,\n",
    "    hidden_continuous_size=16, # 연속 변수의 표현 차원수\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=8,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    log_val_interval=10,  # uncomment for best val on last log_val_interval evaluations\n",
    "    # optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff085b5",
   "metadata": {},
   "source": [
    "#### 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa2ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf9723b40f4752a9aeef5b8840916a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36d215826046bb831d900c4ed03c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438f97c8b00e445cb106c4375bb6e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 1041254.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358477da08594986bf8e99ec4aad0970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 155189.375 >= min_delta = 0.0001. New best score: 886065.500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4752f86f214c20af241cc581ab7ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 93943.750 >= min_delta = 0.0001. New best score: 792121.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887b1a5f5e6d44f49d1531786579b3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9ca3c6a2ad40e7974bb62ccb1f44ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 53778.000 >= min_delta = 0.0001. New best score: 738343.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dfce9470a1446fbed87e2769d4e39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41b2550d3cd430d8bc5def138d76c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2270556765de4f94aa840e5a1382700d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 60813.562 >= min_delta = 0.0001. New best score: 677530.188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9a2b6ba71e4b48a9a84641704e3539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 10629.125 >= min_delta = 0.0001. New best score: 666901.062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0654bd3dca54c4996695ce5d805d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182db325240943748a0ee2dd74a25441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa51c75c43004c1eb68736c3e341b925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c289fbd49d814160b7f8da681949f239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 44252.625 >= min_delta = 0.0001. New best score: 622648.438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c87ffb13e9247f1bd982b2e47deeb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034b50b1614541ee95035c0bd477d6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 43318.875 >= min_delta = 0.0001. New best score: 579329.562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaa562455b04960978563dc81f3da4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d45204a456a45348c1024a725f85af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5f743688bc4675907389da74754ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66321b5e4b194b3aae0da8effc1937a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 31407.875 >= min_delta = 0.0001. New best score: 547921.688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e992028c2e2453ea26460b90b9fbe4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9068eb965e54819bdd695c60897ff75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9795f6f8f6414d87bf608f23e40a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebd491aeaaf446c97f80cc5da2b31ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25db02ecbf54d8390eee69ce58229f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ca6ea66da54efab30bbee26047eb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95086c3d2fb4da692fc4342fe4bc558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf400e10c3f4ac49b488d14ad5379c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6bf1915d6f49f481f906e921d3ca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fa55c0a8cf4763b76aaa2f77f0e85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric train_loss did not improve in the last 10 records. Best score: 547921.688. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    # check_val_every_n_epoch=1,\n",
    "    #fast_dev_run=True,\n",
    "    # gradient_clip_val=0.1,\n",
    "    # limit_train_batches=100,\n",
    "    # limit_val_batches=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b18ff",
   "metadata": {},
   "source": [
    "### 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35308b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 21:55:39,273] A new study created in memory with name: no-name-473e4c65-c478-4f51-9637-1badf1a86811\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:142: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gradient_clip_val = trial.suggest_loguniform(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:168: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout=trial.suggest_uniform(\"dropout\", *dropout_range),\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:222: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  model.hparams.learning_rate = trial.suggest_loguniform(\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 173 K  | train\n",
      "3  | prescalers                         | ModuleDict                      | 476    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 32.0 K | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 40.5 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 30.3 K | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 39.8 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 39.8 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 39.8 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 39.8 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 79.2 K | train\n",
      "12 | lstm_decoder                       | LSTM                            | 79.2 K | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 19.8 K | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 198    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 49.6 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 29.4 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 20.0 K | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 39.8 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 20.0 K | train\n",
      "20 | output_layer                       | Linear                          | 700    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "773 K     Trainable params\n",
      "0         Non-trainable params\n",
      "773 K     Total params\n",
      "3.093     Total estimated model params size (MB)\n",
      "318       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980b3ad045ca4869ab068f5c7bf7455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161a57ede85c472789fe6c6da9c34265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9c6e9428e4a9d9d207f13b1aa5cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hacker/.pyenv/versions/3.11.12/lib/python3.11/site-packages/pytorch_forecasting/metrics/base_metrics.py:897: UserWarning: Loss is not finite. Resetting it to 1e9\n",
      "  warnings.warn(\"Loss is not finite. Resetting it to 1e9\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4278b7d38a554b6dbc28a2468fc623eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[I 2025-05-06 21:57:41,392] Trial 0 finished with value: 1500066.375 and parameters: {'gradient_clip_val': 0.2954643463723628, 'hidden_size': 99, 'dropout': 0.21918646593882604, 'hidden_continuous_size': 34, 'attention_head_size': 2, 'learning_rate': 0.0015266674010786445}. Best is trial 0 with value: 1500066.375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val': 0.2954643463723628, 'hidden_size': 99, 'dropout': 0.21918646593882604, 'hidden_continuous_size': 34, 'attention_head_size': 2, 'learning_rate': 0.0015266674010786445}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# 파라미터 튜닝\n",
    "\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=os.path.join(BASE_PATH, \"TFT\"),\n",
    "    n_trials=1, # 몇번 시도할지\n",
    "    max_epochs=2,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,\n",
    "    verbose=2,\n",
    "    # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "with open(os.path.join(BASE_PATH, \"test_study.pkl\"), \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26099b",
   "metadata": {},
   "source": [
    "### 훈련후 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84846ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x143dc6050>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e091ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/Volumes/KUUWANGE/WORKSPACE/P_Personal/SOYBEAN/scripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# best_model_path = \"/content/drive/MyDrive/crop/tf_logger/lightning_logs/version_6/checkpoints/epoch=10-step=110.ckpt\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m (best_model_path)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m best_tft = \u001b[43mTemporalFusionTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# calcualte mean absolute error on validation set\u001b[39;00m\n\u001b[32m     11\u001b[39m predictions = best_tft.predict(val_dataloader, return_y=\u001b[38;5;28;01mTrue\u001b[39;00m, trainer_kwargs=\u001b[38;5;28mdict\u001b[39m(accelerator=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1581\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1499\u001b[39m     **kwargs: Any,\n\u001b[32m   1500\u001b[39m ) -> Self:\n\u001b[32m   1501\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1503\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1579\u001b[39m \n\u001b[32m   1580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1582\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1587\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1588\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:63\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m map_location = map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     checkpoint = \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[32m     66\u001b[39m checkpoint = _pl_migrate_checkpoint(\n\u001b[32m     67\u001b[39m     checkpoint, checkpoint_path=(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     68\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:59\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(path_or_url, map_location, weights_only)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.hub.load_state_dict_from_url(\n\u001b[32m     54\u001b[39m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[32m     55\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     56\u001b[39m         weights_only=weights_only,\n\u001b[32m     57\u001b[39m     )\n\u001b[32m     58\u001b[39m fs = get_filesystem(path_or_url)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(\n\u001b[32m     61\u001b[39m         f,\n\u001b[32m     62\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     63\u001b[39m         weights_only=weights_only,\n\u001b[32m     64\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/fsspec/spec.py:1310\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1309\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1319\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/fsspec/implementations/local.py:201\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/fsspec/implementations/local.py:365\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    364\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/fsspec/implementations/local.py:370\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.path, mode=\u001b[38;5;28mself\u001b[39m.mode)\n\u001b[32m    371\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    372\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: '/Volumes/KUUWANGE/WORKSPACE/P_Personal/SOYBEAN/scripts'"
     ]
    }
   ],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "# best_model_path = \"/content/drive/MyDrive/crop/tf_logger/lightning_logs/version_6/checkpoints/epoch=10-step=110.ckpt\"\n",
    "print (best_model_path)\n",
    "\n",
    "\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# calcualte mean absolute error on validation set\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "MAE()(predictions.output, predictions.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True, return_index=True)\n",
    "\n",
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)\n",
    "\n",
    "\n",
    "for idx in range(13):  # plot 10 examples\n",
    "  plot_ind = best_tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True, show_future_observed=True, plot_attention=False)\n",
    "  idx_name = (raw_predictions.index['group'][idx])\n",
    "  plot_ind.suptitle(f\"Group: {idx_name}\")\n",
    "  # plot_ind.set(title=f\"Group: {idx_name}\")\n",
    "  plot_ind.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import SMAPE\n",
    "\n",
    "# calcualte metric by which to display\n",
    "#predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "\n",
    "#print (predictions.output)\n",
    "\n",
    "#y_pred = predictions.y[0].cpu()\n",
    "\n",
    "\n",
    "\n",
    "# 예측\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\"), return_index=True)\n",
    "\n",
    "# 예측값과 실제값 (둘 다 CPU로 옮겨서 계산)\n",
    "y_pred = predictions.output.cpu()\n",
    "y_true = predictions.y[0].cpu()\n",
    "\n",
    "# SMAPE 인스턴스 생성\n",
    "smape = SMAPE()\n",
    "\n",
    "print (y_pred)\n",
    "print (y_true)\n",
    "# 전체 평균 SMAPE 계산\n",
    "smape_score = smape(y_pred, y_true)\n",
    "\n",
    "print(f\"📊 SMAPE (전체 평균): {smape_score * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# mean_losses = SMAPE(reduction=\"none\")(predictions.output, predictions.y).mean(1)\n",
    "# indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "# for idx in range(10):  # plot 10 examples\n",
    "    # best_tft.plot_prediction(\n",
    "    #     raw_predictions.x,\n",
    "    #     raw_predictions.output,\n",
    "    #     idx=indices[idx],\n",
    "    #     add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles),\n",
    "    # )\n",
    "\n",
    "\n",
    "predictions = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(predictions.x, predictions.output)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
